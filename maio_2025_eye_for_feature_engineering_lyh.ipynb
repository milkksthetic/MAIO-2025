{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c1ccaa5e-91a8-4942-b65f-9ea8e7598cfc",
      "metadata": {
        "id": "c1ccaa5e-91a8-4942-b65f-9ea8e7598cfc"
      },
      "source": [
        "# An eye for feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42f21ea5-84c9-465b-802d-7930245c5cd6",
      "metadata": {
        "id": "42f21ea5-84c9-465b-802d-7930245c5cd6"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "f34dd59c-09b9-457a-8a11-6daccfb97ae0",
      "metadata": {
        "id": "f34dd59c-09b9-457a-8a11-6daccfb97ae0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "c11b1c79-665f-48c4-8f92-2e576f15e5be",
      "metadata": {
        "id": "c11b1c79-665f-48c4-8f92-2e576f15e5be"
      },
      "outputs": [],
      "source": [
        "dino = pd.read_csv(\"https://storage.googleapis.com/aiolympiadmy/maio_2025_eye_for_feature_engineering.csv\", index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "93d018b3-48b0-449a-8d1f-ec9d8b0ea361",
      "metadata": {
        "id": "93d018b3-48b0-449a-8d1f-ec9d8b0ea361"
      },
      "outputs": [],
      "source": [
        "X, y = dino[[\"feature1\", \"feature2\"]], dino[\"class\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "6519c3ca-d7ad-4e0d-9099-3d12699cde1c",
      "metadata": {
        "id": "6519c3ca-d7ad-4e0d-9099-3d12699cde1c"
      },
      "outputs": [],
      "source": [
        "def create_new_feature(X):\n",
        "    return X[\"feature1\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "85947e3a-1379-44fe-a88d-d25b9e499218",
      "metadata": {
        "id": "85947e3a-1379-44fe-a88d-d25b9e499218"
      },
      "outputs": [],
      "source": [
        "# Create the feature itself\n",
        "X[\"feature3\"] = create_new_feature(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "3ec4bd09-2d89-4d3a-a373-06ce9e7fc5d2",
      "metadata": {
        "id": "3ec4bd09-2d89-4d3a-a373-06ce9e7fc5d2"
      },
      "outputs": [],
      "source": [
        "logreg = LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "a0910959-c781-49cb-b46b-665e638fce60",
      "metadata": {
        "id": "a0910959-c781-49cb-b46b-665e638fce60"
      },
      "outputs": [],
      "source": [
        "logreg.fit(X, y)\n",
        "y_pred_logreg = logreg.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "1456408e-f1e3-4843-8266-f8d6600f8a4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1456408e-f1e3-4843-8266-f8d6600f8a4b",
        "outputId": "177d8403-acab-4fe8-cba5-da26cce9868e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logreg precision / recall / f1_score 0.0 0.0 0.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Logreg precision / recall / f1_score\",\n",
        "    precision_score(y, y_pred_logreg, zero_division=0, pos_label=1, average=\"binary\"),\n",
        "    recall_score(y, y_pred_logreg, zero_division=0, pos_label=1, average=\"binary\"),\n",
        "    f1_score(y, y_pred_logreg, zero_division=0, pos_label=1, average=\"binary\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05900d7f-46e9-4002-be6c-27c6dcab44a5",
      "metadata": {
        "id": "05900d7f-46e9-4002-be6c-27c6dcab44a5"
      },
      "source": [
        "## Your task"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "296c6493-1350-466a-8b37-b7e0280a8e12",
      "metadata": {
        "id": "296c6493-1350-466a-8b37-b7e0280a8e12"
      },
      "source": [
        "Above is a peculiar dataset passed through a logistic regression classifier. Notice that the baseline example provided above scores 0 for precision, recall and F1 score. (Google / ask ChatGPT and friends if you're learning of these terms for the first time!)\n",
        "\n",
        "Do what you can to raise the F1 score as much as possible, subject to the following restrictions:\n",
        "\n",
        "- You cannot edit the existing model prediction logic in the Your Submission section:\n",
        "    - except for the cell containing `create_new_feature()` itself\n",
        "    - except for the cell marked for you to import new libraries\n",
        "- You can still add new code cells to this notebooks under the Scratchpad section below. Do all your exploration and testing here. However, code in Your Submission must not depend on code in your Scratchpad in any way. Only code from Your Submission will be run during evaluation.\n",
        "\n",
        "This challenge will be graded via notebook submission only. Scoring as follows:\n",
        "\n",
        "- Up to 10 pts for model performance, F1 score X 10. Partial credit may be granted for incomplete submissions at discretion. So show your work below!\n",
        "- +3 pts if F1 score >= 0.5 and no neural networks are involved. Neural networks here are strictly defined as the use of learnable weights and biases\n",
        "- +2 pts if F1 score >= 0.5 and the `%%timeit` cell reports runtime <= 10 milliseconds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06f83b23-4589-4efe-a6d2-3b72cbc4b7cd",
      "metadata": {
        "id": "06f83b23-4589-4efe-a6d2-3b72cbc4b7cd"
      },
      "source": [
        "### Scratchpad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "f7ef4978-bfc1-48ed-8753-e1186379c807",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7ef4978-bfc1-48ed-8753-e1186379c807",
        "outputId": "49363431-3d9d-4ade-9d42-389aa16fc3de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discovered class 1 cluster centers: [[51.77156364 82.28438182]\n",
            " [80.156      33.23205   ]\n",
            " [30.25643333 61.53846667]]\n",
            "Logreg precision / recall 1.0 1.0 1.0\n"
          ]
        }
      ],
      "source": [
        "# Write all your exploratory code here\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np # mathematical transformation\n",
        "from sklearn.cluster import KMeans # automatically discover clusters\n",
        "\n",
        "\"\"\"STEP 1: Find clusters using only class 1 points\"\"\"\n",
        "# only extract the points where it is class 1\n",
        "class_1_points = X[y == 1]  # only use feature1 and feature2 for clustering\n",
        "\n",
        "# set number of clusters (k), originally used 1, increased until 3\n",
        "optimal_k = 3\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "\n",
        "# train kmeans clustering using only 'feature1' and 'feature2' from class 1 points\n",
        "kmeans.fit(class_1_points[[\"feature1\", \"feature2\"]])\n",
        "\n",
        "# get discovered class 1 cluster centers\n",
        "cluster_centers = kmeans.cluster_centers_\n",
        "print(\"Discovered class 1 cluster centers:\", cluster_centers)  # print found cluster locations\n",
        "\n",
        "\"\"\"STEP 2: Feature engineering function\"\"\"\n",
        "def create_new_feature(X):\n",
        "  sigma = 15  # control the spread of influence (originally tried 20 and 10)\n",
        "  cluster_weight = 2  # scaling factor to increase cluster importance\n",
        "\n",
        "  # compute weighted Gaussian cluster scores for each point based on distance to the cluster centres\n",
        "  cluster_score = sum(\n",
        "      cluster_weight * np.exp(-((X[\"feature1\"] - cx) ** 2 + (X[\"feature2\"] - cy) ** 2) / (2 * sigma ** 2))\n",
        "      for cx, cy in cluster_centers\n",
        "  )\n",
        "\n",
        "  # LATEST: add a binary indicator for points near discovered clusters\n",
        "  # assigns strong weight if point is within 9 units of any cluster centre (originally tried 15 and 10)\n",
        "  binary_flag = sum(\n",
        "      ((X[\"feature1\"] > cx - 9) & (X[\"feature1\"] < cx + 9) &\n",
        "        (X[\"feature2\"] > cy - 9) & (X[\"feature2\"] < cy + 9))\n",
        "      for cx, cy in cluster_centers\n",
        "  ).astype(int) * 3\n",
        "\n",
        "  # interaction term to capture feature relationships\n",
        "  interaction = (X[\"feature1\"] * X[\"feature2\"]) / 600\n",
        "\n",
        "  return cluster_score + interaction + binary_flag\n",
        "\n",
        "# DO NOT EDIT BELOW - scoring cell\n",
        "X[\"feature3\"] = create_new_feature(X)\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X, y)\n",
        "y_pred_logreg = logreg.predict(X)\n",
        "\n",
        "print(\"Logreg precision / recall\",\n",
        "    precision_score(y, y_pred_logreg, zero_division=0, pos_label=1, average=\"binary\"),\n",
        "    recall_score(y, y_pred_logreg, zero_division=0, pos_label=1, average=\"binary\"),\n",
        "    f1_score(y, y_pred_logreg, zero_division=0, pos_label=1, average=\"binary\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dd5eec5-4647-4e18-96e2-0bf7a85b3c6d",
      "metadata": {
        "id": "2dd5eec5-4647-4e18-96e2-0bf7a85b3c6d"
      },
      "source": [
        "## Your submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "248b18f1-9e86-48e8-81dc-25b858031147",
      "metadata": {
        "id": "248b18f1-9e86-48e8-81dc-25b858031147"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "c47d6de9-6efc-438a-977b-f2c40b3acefd",
      "metadata": {
        "id": "c47d6de9-6efc-438a-977b-f2c40b3acefd"
      },
      "outputs": [],
      "source": [
        "# EDIT ME - import additional libraries here\n",
        "# e.g. import this\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "34b9a4b1-3ac3-44fc-a9e2-68663bce20c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34b9a4b1-3ac3-44fc-a9e2-68663bce20c3",
        "outputId": "0a709099-9572-49d0-9dcf-809c52e52666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discovered class 1 cluster centers: [[51.77156364 82.28438182]\n",
            " [80.156      33.23205   ]\n",
            " [30.25643333 61.53846667]]\n"
          ]
        }
      ],
      "source": [
        "# EDIT ME\n",
        "\"\"\"STEP 1: Find clusters using only class 1 points\"\"\"\n",
        "# only extract the points where it is class 1\n",
        "class_1_points = X[y == 1]  # only use feature1 and feature2 for clustering\n",
        "\n",
        "# set number of clusters (k), originally used 1, increased until 3\n",
        "optimal_k = 3\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "\n",
        "# train kmeans clustering using only 'feature1' and 'feature2' from class 1 points\n",
        "kmeans.fit(class_1_points[[\"feature1\", \"feature2\"]])\n",
        "\n",
        "# get discovered class 1 cluster centers\n",
        "cluster_centers = kmeans.cluster_centers_\n",
        "print(\"Discovered class 1 cluster centers:\", cluster_centers)  # print found cluster locations\n",
        "\n",
        "\"\"\"STEP 2: Feature engineering function\"\"\"\n",
        "def create_new_feature(X):\n",
        "  sigma = 15  # control the spread of influence (originally tried 20 and 10)\n",
        "  cluster_weight = 2  # scaling factor to increase cluster importance\n",
        "\n",
        "  # compute weighted Gaussian cluster scores for each point based on distance to the cluster centres\n",
        "  cluster_score = sum(\n",
        "      cluster_weight * np.exp(-((X[\"feature1\"] - cx) ** 2 + (X[\"feature2\"] - cy) ** 2) / (2 * sigma ** 2))\n",
        "      for cx, cy in cluster_centers\n",
        "  )\n",
        "\n",
        "  # add a binary indicator for points near discovered clusters\n",
        "  # assigns strong weight if point is within 9 units of any cluster centre (originally tried 15 and 10)\n",
        "  binary_flag = sum(\n",
        "      ((X[\"feature1\"] > cx - 9) & (X[\"feature1\"] < cx + 9) &\n",
        "        (X[\"feature2\"] > cy - 9) & (X[\"feature2\"] < cy + 9))\n",
        "      for cx, cy in cluster_centers\n",
        "  ).astype(int) * 3\n",
        "\n",
        "  # interaction term to capture feature relationships\n",
        "  interaction = (X[\"feature1\"] * X[\"feature2\"]) / 600\n",
        "\n",
        "  return cluster_score + interaction + binary_flag\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "77fe6fa9-81a7-4700-aec2-ea12369915aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77fe6fa9-81a7-4700-aec2-ea12369915aa",
        "outputId": "fbd6ce86-7e7e-4d73-accd-c1724cf09042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.34 ms ± 471 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 10\n",
        "# DO NOT EDIT - timing cell\n",
        "create_new_feature(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "6b19f4bd-8087-43c7-8fdf-9f949d038852",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b19f4bd-8087-43c7-8fdf-9f949d038852",
        "outputId": "a0ade770-b908-4c4c-9fe2-7993b0ecdac8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logreg precision / recall 1.0 1.0 1.0\n"
          ]
        }
      ],
      "source": [
        "# DO NOT EDIT - scoring cell\n",
        "X[\"feature3\"] = create_new_feature(X)\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X, y)\n",
        "y_pred_logreg = logreg.predict(X)\n",
        "\n",
        "print(\"Logreg precision / recall\",\n",
        "    precision_score(y, y_pred_logreg, zero_division=0, pos_label=1, average=\"binary\"),\n",
        "    recall_score(y, y_pred_logreg, zero_division=0, pos_label=1, average=\"binary\"),\n",
        "    f1_score(y, y_pred_logreg, zero_division=0, pos_label=1, average=\"binary\")\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:ml]",
      "language": "python",
      "name": "conda-env-ml-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
